{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2\n",
    "\n",
    "- Build and train a MLP Model to classify Mnist dataset\n",
    "\n",
    " 1- MLP Network accepts 1D data. So we should flatten our 2D image, then print the dimension of the result arrays.\n",
    " \n",
    " 2- Normalize data by rescaling them to (0,1) \n",
    " \n",
    " 3- Convert label arrays to 1-hot representation (`keras.utils.to_categorical`)\n",
    " \n",
    " 4- Define Model\n",
    "    * Hidden Layer 1: Fully Conncted + Relu Activition (e.g. 512 Nuerons)\n",
    "    * Hidden Layer 2: Fully Connected + Relu Activition (e.g. 512 Neurons)\n",
    "    * Outout Layer: Fully Connected + Softmax Activition\n",
    " \n",
    " \n",
    "- Build and train a CNN+MLP deep learning model with Keras with followings specs for MNIST dataset:\n",
    "\n",
    "    1. Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
    "    2. Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
    "    3. MaxPooling2D(pool_size=(2, 2))\n",
    "    4. Dense(128, activation='relu')\n",
    "    5. Dense(num_classes, activation='softmax')\n",
    "\n",
    "    Also build another model with BatchNormalization and Dropout.\n",
    "    Compare these two CNN + MLP models performance for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# CNN architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# MLP architecture\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import RandomNormal\n",
    "# MNIST\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Train and Test\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (60000, 784)\n",
      "Shape of X_test: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Flattening Image\n",
    "x_train = np.reshape(x_train, [-1, 28*28])  # we want 784 samples\n",
    "x_test = np.reshape(x_test,[-1, 28*28])\n",
    "\n",
    "# Displaying Resulting Dimensions\n",
    "print(f'Shape of X_train: {x_train.shape}')\n",
    "print(f'Shape of X_test: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
